{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_by_patern(folder, pattern):\n",
    "    \n",
    "    # Initialize an empty list to store matching files\n",
    "    config_files = []\n",
    "\n",
    "    # Use glob to find files matching the current pattern\n",
    "    matching_files = glob.glob(os.path.join(folder, pattern))\n",
    "    config_files.extend(matching_files)\n",
    "    \n",
    "    return config_files\n",
    "\n",
    "def read_acc_from_log(log_path):\n",
    "    # Initialize empty lists to store metrics\n",
    "    mean_iou, micro_iou, macro_iou, accuracy, recall, precision, f1 = [], [], [], [], [], [], []\n",
    "\n",
    "    # Open the log file and process each line\n",
    "    inside_section = False\n",
    "    with open(log_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # print(file.read())\n",
    "        for line in lines[-8:]:\n",
    "            if \"Overall\" in line:\n",
    "                inside_section = True\n",
    "            elif inside_section:\n",
    "                metric_name, metric_value = line.split(\"---->\")\n",
    "                metric_name = metric_name.split('-')[-1].strip()\n",
    "                metric_value = float(metric_value.strip())\n",
    "                if metric_name == \"Mean IOU\":\n",
    "                    mean_iou.append(metric_value)\n",
    "                elif metric_name == \"Micro IOU\":\n",
    "                    micro_iou.append(metric_value)\n",
    "                elif metric_name == \"Macro IOU\":\n",
    "                    macro_iou.append(metric_value)\n",
    "                elif metric_name == \"Accuracy\":\n",
    "                    accuracy.append(metric_value)\n",
    "                elif metric_name == \"Recall\":\n",
    "                    recall.append(metric_value)\n",
    "                elif metric_name == \"Precision\":\n",
    "                    precision.append(metric_value)\n",
    "                elif metric_name == \"F1\":\n",
    "                    f1.append(metric_value)\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Mean IoU': mean_iou,\n",
    "        'Micro IoU': micro_iou,\n",
    "        'Macro IoU': macro_iou,\n",
    "        'Accuracy': accuracy,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'F1': f1\n",
    "    })\n",
    "\n",
    "    # Print the DataFrame\n",
    "    # print(df)\n",
    "    return df\n",
    "\n",
    "def read_param_from_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    extracted_params = {}\n",
    "    for section, params in config.items():\n",
    "        if isinstance(params, dict):\n",
    "            for key, value in params.items():\n",
    "                extracted_params[key] = value\n",
    "    \n",
    "    df_params = pd.DataFrame([extracted_params])\n",
    "    # print(df_params)\n",
    "    return df_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/exports/csce/datastore/geos/users/s2135982/rivertools/mlfluv/script\n",
      "['experiments/3001', 'experiments/3002', 'experiments/2001', 'experiments/2002', 'experiments/1001', 'experiments/1002']\n",
      "experiments/3001/preds.log\n",
      "experiments/3001/fine_tune_17/preds.log\n",
      "            name                       test_paths     train_paths which_label  \\\n",
      "0  MLFluvDataset  data/labelled_data/test_dataset  data/fold_data       ESAWC   \n",
      "\n",
      "   convert_to_tif  fluv_point_only  handle_nan_in_sentinel  move_data  \\\n",
      "0            True            False                   False       True   \n",
      "\n",
      "   remap_to_sedi  distill_lamda  ...    train_fold  valid_fold  window_size  \\\n",
      "0          False           0.75  ...  [0, 1, 2, 3]         [4]        512.0   \n",
      "\n",
      "   Mean IoU Micro IoU Macro IoU Accuracy  Recall Precision     F1  \n",
      "0     0.333     0.822     0.333    0.972   0.902     0.902  0.902  \n",
      "\n",
      "[1 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "# Read the log file\n",
    "log_file = 'preds.log'\n",
    "config_file = 'config.yml'\n",
    "\n",
    "exp_root = 'experiments'\n",
    "\n",
    "exp_paths = [os.path.join(exp_root, exp) for exp in os.listdir(exp_root)]\n",
    "print(exp_paths)\n",
    "\n",
    "for exp_path in exp_paths[:1]:\n",
    "\n",
    "    init_config = find_files_by_patern(exp_path, 'config*.yml')[0]\n",
    "    init_accuracy = find_files_by_patern(exp_path, 'preds.log')[0]\n",
    "    print(init_accuracy)\n",
    "\n",
    "    # df = read_acc_from_log(init_accuracy)\n",
    "\n",
    "    \n",
    "\n",
    "    fine_tune_paths = [os.path.join(exp_path, folder) for folder in os.listdir(exp_path) if folder.startswith('fine_tune')]\n",
    "    # print(len(fine_tune_paths))\n",
    "    # print(fine_tune_paths[0])\n",
    "    dfs = []\n",
    "    for fine_tune_path in fine_tune_paths[:1]:\n",
    "        fine_tune_config = find_files_by_patern(fine_tune_path, 'config*.yml')[0]\n",
    "        fine_tune_accuracy = find_files_by_patern(fine_tune_path, 'preds.log')[0]\n",
    "        \n",
    "        print(fine_tune_accuracy)\n",
    "        df_acc = read_acc_from_log(fine_tune_accuracy)\n",
    "        df_param = read_param_from_config(fine_tune_config)\n",
    "\n",
    "        # Join these two dataframes\n",
    "        merged_df = pd.concat([df_param, df_acc], axis=0, ignore_index=True)\n",
    "        # Stack two rows to one row\n",
    "        df_ft = pd.DataFrame([merged_df.stack().values], columns=merged_df.columns)\n",
    "        dfs.append(df_ft)\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rivtools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
